{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project Title: Managing a DevSecOps Pipeline with Secure Development and Operations Author: Tariq Ahmed Mentor: Akash Mahajan , Sunesh Govindaraj , Ayush Priya , Priyam Singh This report was created as part of my internship at Kloudle as a DevSecOps Engineer. The report documents the tasks I worked on as part of my internship as well as the solutions I created for them along with various notes on issues I faced and their rectification measures.","title":"Introduction"},{"location":"aws/","text":"Objective The aim of this section is to shift the entire setup from local machine to AWS Cloud and solve the 10th point of the Problem Statement under Task 1. About AWS Amazon Web Services (AWS) is the world's most comprehensive and broadly adopted cloud platform, offering over 200 fully featured services from data centers globally. Migrating your local/on-prem infrastructure to cloud (AWS) can help reduce costs of operations, increase IT staff productivity, and reduce downtime. Setup EC2 Instances Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is a service that enables business subscribers to run application programs in the computing environment. It can serve as a practically unlimited set of VMs. An EC2 instance is a virtual server in Amazon's EC2 for running applications on the AWS infrastructure. Instances are created from Amazon Machine Images (AMI). AMIs are like templates that are configured with an OS, CPU power, memory, storage and other networking resources to suit user needs. Steps to create an EC2 instance: Create an AWS account on https://aws.amazon.com . After logging in to your account, select All Services and under the Compute section, click EC2 in the AWS Management Console page. You will be redirected to EC2 Management Console Select Launch EC2 instance . Select AMI of your choice, add security group (firewall rules) and SSH key pair. When adding key pair, the browser will automatically ask to download the private key file. Keep the file safe in directory of your choice. You will need it to establish an SSH connection with the instance. After launch, wait till the instance is up and running. SSH into the instance using the following command. ssh -i /path/to/private-key instance-username@instance-IP-address To get the instance-username for SSH login based on your instance OS/distro, refer this documentation . For an Ubuntu instance, the username is ubuntu . 7. Create three instances; Jenkins instance (master), DAST instance (agent), Production instance. Jenkins Server Spin up an instance for Jenkins server. Automate the installation process of Jenkins, Docker and static analysis tools by running the following script in the Jenkins instance. Note: Initially, I tried running all the scans in Jenkins instance via pipeline. But the instance crashed/hung when running the OWASP ZAP scan. Since I'm using a Free Tier version, I can only start instances with 1GB memory, which isn't sufficient to run all these scans. To solve this issue, I'm using a Master-Agent architecture in which the DAST scan will be allocated to an Agent (separate instance). #!/bin/bash sudo apt update # Install Java sudo apt install -y default-jre default-jdk # Install Jenkins wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - && sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' && sudo apt install -y jenkins && sudo systemctl start jenkins # Install Docker sudo curl -fsSL https://get.docker.com -o get-docker.sh && sudo sh get-docker.sh && sudo usermod -aG docker jenkins # Install Python3 and Pip3 sudo apt install -y python3-pip # Install NodeJs and NPM sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - && sudo apt install -y nodejs # Install NodeJsScan (SAST) pip3 install njsscan # Install AuditJS (SAST) sudo npm install -g auditjs # Install OWASP Dependency-Check (SCA) wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip && wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip.asc && unzip ~/dependency-check-6.2.2-release.zip # Install CycloneDX (SBoM) sudo npm install -g @cyclonedx/bom # Install JSHint (Code Linting) sudo npm install -g jshint # Install ESLint (Code Linting) # Note: To use eslint, manually create a .eslintrc.json file in the `jenkins` home directory. # Copy the file content from documentation sudo npm install -g eslint Production Server Install docker on the production server the same way you installed it on the Jenkins server.","title":"Shift Local Setup to AWS"},{"location":"aws/#objective","text":"The aim of this section is to shift the entire setup from local machine to AWS Cloud and solve the 10th point of the Problem Statement under Task 1. About AWS Amazon Web Services (AWS) is the world's most comprehensive and broadly adopted cloud platform, offering over 200 fully featured services from data centers globally. Migrating your local/on-prem infrastructure to cloud (AWS) can help reduce costs of operations, increase IT staff productivity, and reduce downtime.","title":"Objective"},{"location":"aws/#setup-ec2-instances","text":"Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. It is a service that enables business subscribers to run application programs in the computing environment. It can serve as a practically unlimited set of VMs. An EC2 instance is a virtual server in Amazon's EC2 for running applications on the AWS infrastructure. Instances are created from Amazon Machine Images (AMI). AMIs are like templates that are configured with an OS, CPU power, memory, storage and other networking resources to suit user needs. Steps to create an EC2 instance: Create an AWS account on https://aws.amazon.com . After logging in to your account, select All Services and under the Compute section, click EC2 in the AWS Management Console page. You will be redirected to EC2 Management Console Select Launch EC2 instance . Select AMI of your choice, add security group (firewall rules) and SSH key pair. When adding key pair, the browser will automatically ask to download the private key file. Keep the file safe in directory of your choice. You will need it to establish an SSH connection with the instance. After launch, wait till the instance is up and running. SSH into the instance using the following command. ssh -i /path/to/private-key instance-username@instance-IP-address To get the instance-username for SSH login based on your instance OS/distro, refer this documentation . For an Ubuntu instance, the username is ubuntu . 7. Create three instances; Jenkins instance (master), DAST instance (agent), Production instance.","title":"Setup EC2 Instances"},{"location":"aws/#jenkins-server","text":"Spin up an instance for Jenkins server. Automate the installation process of Jenkins, Docker and static analysis tools by running the following script in the Jenkins instance. Note: Initially, I tried running all the scans in Jenkins instance via pipeline. But the instance crashed/hung when running the OWASP ZAP scan. Since I'm using a Free Tier version, I can only start instances with 1GB memory, which isn't sufficient to run all these scans. To solve this issue, I'm using a Master-Agent architecture in which the DAST scan will be allocated to an Agent (separate instance). #!/bin/bash sudo apt update # Install Java sudo apt install -y default-jre default-jdk # Install Jenkins wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - && sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' && sudo apt install -y jenkins && sudo systemctl start jenkins # Install Docker sudo curl -fsSL https://get.docker.com -o get-docker.sh && sudo sh get-docker.sh && sudo usermod -aG docker jenkins # Install Python3 and Pip3 sudo apt install -y python3-pip # Install NodeJs and NPM sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - && sudo apt install -y nodejs # Install NodeJsScan (SAST) pip3 install njsscan # Install AuditJS (SAST) sudo npm install -g auditjs # Install OWASP Dependency-Check (SCA) wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip && wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip.asc && unzip ~/dependency-check-6.2.2-release.zip # Install CycloneDX (SBoM) sudo npm install -g @cyclonedx/bom # Install JSHint (Code Linting) sudo npm install -g jshint # Install ESLint (Code Linting) # Note: To use eslint, manually create a .eslintrc.json file in the `jenkins` home directory. # Copy the file content from documentation sudo npm install -g eslint","title":"Jenkins Server"},{"location":"aws/#production-server","text":"Install docker on the production server the same way you installed it on the Jenkins server.","title":"Production Server"},{"location":"complete_pipeline/","text":"Objective The aim of this section is to show the complete CI/CD pipeline structure and solve the points 1-8 in Problem Statement under Task 1. Complete Pipeline The following is the complete pipeline to perform multiple scans on the application and then deploy it in Production VM. pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=<PASSWORD> MYSQL_RANDOM_ROOT_PASSWORD=<ROOT_PASSWORD> MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/ && mkdir ~/reports && chmod 777 ~/reports' } } stage('NodeJsScan Analysis') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs Analysis') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } stage ('OWASP Dependency-Check Analysis') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } } stage('OWASP ZAP Analysis') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.101:9090 -r zap-report.html -l PASS || true' } } stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } } stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna && docker rmi mysql:5.7' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env tariq@192.168.56.102:~/' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } }","title":"Complete Pipeline"},{"location":"complete_pipeline/#objective","text":"The aim of this section is to show the complete CI/CD pipeline structure and solve the points 1-8 in Problem Statement under Task 1.","title":"Objective"},{"location":"complete_pipeline/#complete-pipeline","text":"The following is the complete pipeline to perform multiple scans on the application and then deploy it in Production VM. pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=<PASSWORD> MYSQL_RANDOM_ROOT_PASSWORD=<ROOT_PASSWORD> MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/ && mkdir ~/reports && chmod 777 ~/reports' } } stage('NodeJsScan Analysis') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs Analysis') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } stage ('OWASP Dependency-Check Analysis') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } } stage('OWASP ZAP Analysis') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.101:9090 -r zap-report.html -l PASS || true' } } stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } } stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna && docker rmi mysql:5.7' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env tariq@192.168.56.102:~/' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } }","title":"Complete Pipeline"},{"location":"contents/","text":"The following is the report/documentation for the problem statements stated in the next section. The contents of the report are: Introduction Table of Content Problem Statements Setup of VMs Setup of Jenkins Setup of Production Server SSH Connection between VMs Working of Pipeline Static Analysis Software Composition Analysis Dynamic Analysis Software Bill of Materials Software Code Quality Analysis Complete Pipeline Shift Local Setup to AWS Resources","title":"Table of Content"},{"location":"dynamic_analysis/","text":"Objective The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement under Task 1. About DAST Dynamic Application Security Testing (DAST) is a testing methodology which looks for security vulnerabilities by simulating external attacks on an application while the application is running. DAST performs black-box security testing. OWASP ZAP The Zed Attack Proxy (ZAP) is one of the most widely-used open source tools for DAST. It helps find security vulnerabilities in web applications while its in the development and testing stage. Maintained by OWASP, ZAP has built a huge community of people creating new features and add-ons that make it incredibly versatile. Implementing ZAP analysis with docker is simpler and faster than manual installation. I followed this official documentation . First, pull the ZAP image from docker hub. sudo docker pull owasp/zap2docker-stable We will be running a baseline scan as it is ideal in a CI/CD environment, even against production sites. Docker flags used --rm, remove container after completion -d, run as a background job -u , specify user to run container as -v 'host dir':'container dir', mount volumes Zap CLI flags used -t 'target', specify target to scan -r 'file.html', generate an HTML output report -l level, minimum level to show: PASS, IGNORE, INFO, WARN or FAIL. sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS To run a fullscan script, run the following command sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-full-scan.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS The report zap-report.html , generated on successful completion, will be located in the users home directory. Note: To open .html file in browser from terminal, type open zap-report.html from host terminal. DAST Pipeline Add the following stage in the Jenkins pipelien for performing DAST on DVNA. stage('ZAP Scan') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS || true' } } Note: As we've already seen in Setup of Production Server , DVNA is deployed in a docker container. To perform DAST on DVNA, the application will run in a docker container and the DAST tool will run in another container (as shown earlier in this section). To work with docker containers via Jenkins pipeline, you'll need to add jenkins user to group docker to run docker commands without sudo. sudo usermod -aG docker jenkins sudo reboot Increase VM Disk Space (Optional) While trying to run the Jenkins pipeline, I noticed there was an error during the ZAP scan. On reviewing the container logs, I realized that my VM was out of disk space. So instead of creating a new VM with more disk space (I was currently using the default 10GB), I decided to increase the disk space of the Jenkins VM to 16GB. I followed this documentation . Get location of your Jenkins VM virtual hard disk. Go to Oracle VM VirtualBox Manager -> Jenkins Server -> Settings -> Storage -> Controller: IDE . Increase Disk Size To increase size of virtual disk, type the following command in the terminal (for Linux/MaxOS). VBoxManage modifyhd --resize <NEW-SIZE> <LOCATION-OF-VDI-IMAGE> Check if size changed successfully. VBoxManage showhdinfo <LOCATION-OF-VDI-IMAGE> | grep Capacity Boot from GParted on your VM I followed the same steps as mentioned in the Boot from GParted on your VM section of the documentation . Even after having followed all the steps, the partition was still not set properly. I found the solution to this problem here . In the Jenkins VM, resize the logical volume to use all the existing and free space of the volume group. sudo lvm lvm> lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv lvm> exit After the command above is successful, resize the file system to use the new available space in the logical volume. sudo resize2fs /dev/ubuntu-vg/ubuntu-lv Check if the available space has increased. df -h Note: While running the ZAP scan in pipeline, I got the following error: ERROR [Errno 13] Permission denied: '/zap/wrk/zap-report.html' . To resolve this error, I changed the permissions of /var/lib/jenkins/reports directory. sudo chmod 777 /var/lib/jenkins/report","title":"Dynamic Analysis"},{"location":"dynamic_analysis/#objective","text":"The aim of this section is to perform dynamic analysis using DAST tools on DVNA and solve the 6th point of the Problem Statement under Task 1. About DAST Dynamic Application Security Testing (DAST) is a testing methodology which looks for security vulnerabilities by simulating external attacks on an application while the application is running. DAST performs black-box security testing.","title":"Objective"},{"location":"dynamic_analysis/#owasp-zap","text":"The Zed Attack Proxy (ZAP) is one of the most widely-used open source tools for DAST. It helps find security vulnerabilities in web applications while its in the development and testing stage. Maintained by OWASP, ZAP has built a huge community of people creating new features and add-ons that make it incredibly versatile. Implementing ZAP analysis with docker is simpler and faster than manual installation. I followed this official documentation . First, pull the ZAP image from docker hub. sudo docker pull owasp/zap2docker-stable We will be running a baseline scan as it is ideal in a CI/CD environment, even against production sites. Docker flags used --rm, remove container after completion -d, run as a background job -u , specify user to run container as -v 'host dir':'container dir', mount volumes Zap CLI flags used -t 'target', specify target to scan -r 'file.html', generate an HTML output report -l level, minimum level to show: PASS, IGNORE, INFO, WARN or FAIL. sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS To run a fullscan script, run the following command sudo docker run --rm -d -u zap --name owasp-zap -v ~/:/zap/wrk/ owasp/zap2docker-stable zap-full-scan.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS The report zap-report.html , generated on successful completion, will be located in the users home directory. Note: To open .html file in browser from terminal, type open zap-report.html from host terminal.","title":"OWASP ZAP"},{"location":"dynamic_analysis/#dast-pipeline","text":"Add the following stage in the Jenkins pipelien for performing DAST on DVNA. stage('ZAP Scan') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS || true' } } Note: As we've already seen in Setup of Production Server , DVNA is deployed in a docker container. To perform DAST on DVNA, the application will run in a docker container and the DAST tool will run in another container (as shown earlier in this section). To work with docker containers via Jenkins pipeline, you'll need to add jenkins user to group docker to run docker commands without sudo. sudo usermod -aG docker jenkins sudo reboot","title":"DAST Pipeline"},{"location":"dynamic_analysis/#increase-vm-disk-space-optional","text":"While trying to run the Jenkins pipeline, I noticed there was an error during the ZAP scan. On reviewing the container logs, I realized that my VM was out of disk space. So instead of creating a new VM with more disk space (I was currently using the default 10GB), I decided to increase the disk space of the Jenkins VM to 16GB. I followed this documentation . Get location of your Jenkins VM virtual hard disk. Go to Oracle VM VirtualBox Manager -> Jenkins Server -> Settings -> Storage -> Controller: IDE . Increase Disk Size To increase size of virtual disk, type the following command in the terminal (for Linux/MaxOS). VBoxManage modifyhd --resize <NEW-SIZE> <LOCATION-OF-VDI-IMAGE> Check if size changed successfully. VBoxManage showhdinfo <LOCATION-OF-VDI-IMAGE> | grep Capacity Boot from GParted on your VM I followed the same steps as mentioned in the Boot from GParted on your VM section of the documentation . Even after having followed all the steps, the partition was still not set properly. I found the solution to this problem here . In the Jenkins VM, resize the logical volume to use all the existing and free space of the volume group. sudo lvm lvm> lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv lvm> exit After the command above is successful, resize the file system to use the new available space in the logical volume. sudo resize2fs /dev/ubuntu-vg/ubuntu-lv Check if the available space has increased. df -h Note: While running the ZAP scan in pipeline, I got the following error: ERROR [Errno 13] Permission denied: '/zap/wrk/zap-report.html' . To resolve this error, I changed the permissions of /var/lib/jenkins/reports directory. sudo chmod 777 /var/lib/jenkins/report","title":"Increase VM Disk Space (Optional)"},{"location":"jenkins_setup/","text":"Objective The aim of this section is to set up a Jenkins server for building various CI/CD pipelines and solve the 2nd point of the Problem Statement under Task 1. About Jenkins Jenkins is a Java-based open-source automation software. It automates the repetitive technical tasks involved in the continuous integration and delivery of software Prerequisites VM running Ubuntu 18.04 LTS. Java version 8. OpenJDK version 11. Step 1 - Install Java For setting up the Jenkins server, I followed this documentation as its very clear and easy to follow. The easiest option for installing Java is to use the version packaged with Ubuntu. By default, Ubuntu 18.04 includes OpenJDK version 11, which is an open-source variant of the JRE and JDK. Install the default Java Runtime Environment (JRE) from OpenJDK 11. $ sudo apt install default-jre $ java --version # OpenJDK version Next, install Java Development Kit (JDK) in order to compile and run some specific Java-based software. $ sudo apt install default-jdk $ javac --version # Java Compiler version Step 2 - Install Jenkins First, add the repository key to the system. On success, the system will return OK . wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - Next, append the Debian package repository address to the server\u2019s sources.list file. sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' sudo apt update Install Jenkins and its dependencies. sudo apt install jenkins Step 3 - Start Jenkins Service After all the installation steps, start Jenkins using systemctl. You can view the status of the service, using the 2nd command shown below. sudo systemctl start jenkins sudo systemctl status jenkins Step 4 - Adding Firewall Rules Jenkins uses port 8080 by default. Hence, we'll allow traffic to port 8080 by adding a firewall rule using ufw (uncomplicated firewall). sudo ufw allow 8080 sudo ufw allow OpenSSH # Allow SSH access into the server over the internet sudo ufw enable # Starts the firewall service sudo ufw status # Shows all firewall rules Step 5 - Setting Up Jenkins To set up your installation, visit Jenkins on its default port, 8080, using your server domain name or IP address: http:// :8080. The 'Unlock Jenkins' page asks for administrator password. This password is present in the /var/lib/jenkins/secrets/initialAdminPassword file. Copy and paste the admin password from that file. sudo cat /var/lib/jenkins/secrets/initialAdminPassword You will be given a choice to install suggested plugins or select your own plugins (I chose to install the suggested plugins). After the installation of plugins is complete, you will be prompted to create admin user. You can either create your own, or continue with the default admin. You will see an 'Instance Configuration' page that will ask you to confirm the preferred URL for your Jenkins instance. After confirming the appropriate information, click Save and Finish. You will see a confirmation page confirming that \u201cJenkins is Ready!\u201d Note: If you had moved forward with the default admin and not created a custom admin user, when logging in, use username=\"admin\" and password=\" initialAdminPassword file>\". You can change the admin password from Dashboard \u2192 Admin \u2192 Configure","title":"Setup of Jenkins"},{"location":"jenkins_setup/#objective","text":"The aim of this section is to set up a Jenkins server for building various CI/CD pipelines and solve the 2nd point of the Problem Statement under Task 1. About Jenkins Jenkins is a Java-based open-source automation software. It automates the repetitive technical tasks involved in the continuous integration and delivery of software Prerequisites VM running Ubuntu 18.04 LTS. Java version 8. OpenJDK version 11.","title":"Objective"},{"location":"jenkins_setup/#step-1-install-java","text":"For setting up the Jenkins server, I followed this documentation as its very clear and easy to follow. The easiest option for installing Java is to use the version packaged with Ubuntu. By default, Ubuntu 18.04 includes OpenJDK version 11, which is an open-source variant of the JRE and JDK. Install the default Java Runtime Environment (JRE) from OpenJDK 11. $ sudo apt install default-jre $ java --version # OpenJDK version Next, install Java Development Kit (JDK) in order to compile and run some specific Java-based software. $ sudo apt install default-jdk $ javac --version # Java Compiler version","title":"Step 1 - Install Java"},{"location":"jenkins_setup/#step-2-install-jenkins","text":"First, add the repository key to the system. On success, the system will return OK . wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add - Next, append the Debian package repository address to the server\u2019s sources.list file. sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list' sudo apt update Install Jenkins and its dependencies. sudo apt install jenkins","title":"Step 2 - Install Jenkins"},{"location":"jenkins_setup/#step-3-start-jenkins-service","text":"After all the installation steps, start Jenkins using systemctl. You can view the status of the service, using the 2nd command shown below. sudo systemctl start jenkins sudo systemctl status jenkins","title":"Step 3 - Start Jenkins Service"},{"location":"jenkins_setup/#step-4-adding-firewall-rules","text":"Jenkins uses port 8080 by default. Hence, we'll allow traffic to port 8080 by adding a firewall rule using ufw (uncomplicated firewall). sudo ufw allow 8080 sudo ufw allow OpenSSH # Allow SSH access into the server over the internet sudo ufw enable # Starts the firewall service sudo ufw status # Shows all firewall rules","title":"Step 4 - Adding Firewall Rules"},{"location":"jenkins_setup/#step-5-setting-up-jenkins","text":"To set up your installation, visit Jenkins on its default port, 8080, using your server domain name or IP address: http:// :8080. The 'Unlock Jenkins' page asks for administrator password. This password is present in the /var/lib/jenkins/secrets/initialAdminPassword file. Copy and paste the admin password from that file. sudo cat /var/lib/jenkins/secrets/initialAdminPassword You will be given a choice to install suggested plugins or select your own plugins (I chose to install the suggested plugins). After the installation of plugins is complete, you will be prompted to create admin user. You can either create your own, or continue with the default admin. You will see an 'Instance Configuration' page that will ask you to confirm the preferred URL for your Jenkins instance. After confirming the appropriate information, click Save and Finish. You will see a confirmation page confirming that \u201cJenkins is Ready!\u201d Note: If you had moved forward with the default admin and not created a custom admin user, when logging in, use username=\"admin\" and password=\" initialAdminPassword file>\". You can change the admin password from Dashboard \u2192 Admin \u2192 Configure","title":"Step 5 - Setting Up Jenkins"},{"location":"old%20pipeline/","text":"pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage('Start DVNA and Copy DVNA Code') { steps { sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker start dvna-mysql && docker start dvna-app; docker cp dvna-app:/app/ ~/;\"' sh 'scp -rC tariq@192.168.56.102:~/app ~/ && mkdir ~/reports && chmod 777 ~/reports' } } stage('NodeJsScan Analysis') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs Analysis') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } stage ('OWASP Dependency-Check Analysis') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } } stage('OWASP ZAP Analysis') { steps { sh 'docker run --rm -i -u zap --name owasp-zap -v ~/reports/:/zap/wrk/ owasp/zap2docker-stable zap-baseline.py -t http://192.168.56.102:9090 -r zap-report.html -l PASS || true' } } stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } } stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } } stage ('Stop DVNA') { steps { sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker stop dvna-app && docker stop dvna-mysql;\"' sh 'rm -rf ~/app' sh 'echo \"Scan successfully completed!\"' } } } }","title":"Old pipeline"},{"location":"problem_statements/","text":"TASK-1 Setup the infrastructure, required for the task, on two virtual machines running locally on a laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying DVNA using the pipeline. Setup the Jenkins server and get to know Jenkins pipeline. Deploy the DVNA in the production server; both manually and through Jenkins pipeline. Perform static analysis by using suitable SAST tools on DVNA and generate a report. Getting to know Software Composition Analysis. Perform dynamic analysis by using suitable DAST tools on DVNA and generate a report. Generate Software Bill of Materials of DVNA for all its dependencies. Perform code quality analysis using suitable tools on DVNA and generate a report. Do extensive documentation in markdown and deploy it as a MkDocs website. Move the setup from the local machine to AWS Cloud.","title":"Problem Statements"},{"location":"problem_statements/#task-1","text":"Setup the infrastructure, required for the task, on two virtual machines running locally on a laptop. One VM contains the Jenkins and related infrastructure, and the second VM is for deploying DVNA using the pipeline. Setup the Jenkins server and get to know Jenkins pipeline. Deploy the DVNA in the production server; both manually and through Jenkins pipeline. Perform static analysis by using suitable SAST tools on DVNA and generate a report. Getting to know Software Composition Analysis. Perform dynamic analysis by using suitable DAST tools on DVNA and generate a report. Generate Software Bill of Materials of DVNA for all its dependencies. Perform code quality analysis using suitable tools on DVNA and generate a report. Do extensive documentation in markdown and deploy it as a MkDocs website. Move the setup from the local machine to AWS Cloud.","title":"TASK-1"},{"location":"production_setup/","text":"Objective The aim of this section is to set up a production server for deploying an application (DVNA) and solve the 3rd point of the Problem Statement under Task 1. About DVNA Damn Vulnerable NodeJS Application is a simple NodeJS application to demonstrate OWASP Top 10 Vulnerabilities and guide on fixing and avoiding these vulnerabilities. Prerequisites VM running Ubuntu 18.04 LTS. Docker installed Step 1 - Install docker For docker installation, I followed this documentation as its very simple and easy to execute. curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Alternatively, you can follow this official documentation for docker installation. First, Update the apt package index and install packages to allow apt to use a repository over HTTPS. sudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release Then add Docker\u2019s official GPG key. curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings docker-archive-keyring.gpg Use the following command to set up the stable repository. echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Update the apt package index, and install the latest version of Docker Engine and containerd (a daemon process that manages and runs containers). sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world # Test if docker installation is successful Step 2 - Setup Production Server I followed the official documentation available on GitHub to setup DVNA. DVNA interacts with a MySQL database. Store the db configuration in a file named vars.env . MYSQL_USER=dvna MYSQL_DATABASE=dvna MYSQL_PASSWORD=passw0rd MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_HOST=mysql-db MYSQL_PORT=3306 Start MySQL container (using environment variables in vars.env file). Run an infinite command in detached mode (using -d ), so the command never ends and the container never stops. I used tail -f /dev/null because it is quite light weight and /dev/null is present in most linux images. sudo docker run -d --name dvna-mysql --env-file vars.env mysql:5.7 tail -f /dev/null Start/run the DVNA application. sudo docker run --name dvna-app --env-file vars.env --link dvna-mysql:mysql-db -p 9090:9090 -d appsecco/dvna To test if the containers are running, run a docker ps . You should see two containers running; dvna-app and dvna-mysql. You can stop running containers by using docker stop <container-name-or-id> . For deploying DVNA using Jenkins pipeline, the application will first be run in a docker container in the Jenkins VM. Static and dynamic analysis will be done and only then, will the application be deployed in the production server. Note: You can start the containers again using docker start <container-name-or-id> . When starting, however, you will have to start dvna-mysql container first because dvna-app is dependant on it. The docker commands can only be run as sudo user. There are 2 ways to enable executing docker commands without sudo. Although, you must know, its highly discouraged to do so. (i) Add 'user' to group 'docker' by typing the following command. The changes might not take effect without rebooting your VM. sudo usermod -aG docker $USER sudo reboot (ii) This method should only be used if no other method seems to work, since it grants every user permission to execute and run docker containers. sudo chmod 666 /var/run/docker.sock Follow these steps to completely uninstall/remove nodejs and npm from your VM. Removing Nodejs and Npm using apt package manager. sudo apt-get remove nodejs npm node sudo apt-get purge nodejs Now manually remove .node and .npm folders from your VM. sudo rm -rf /usr/local/bin/npm sudo rm -rf /usr/local/share/man/man1/node* sudo rm -rf /usr/local/lib/dtrace/node.d sudo rm -rf ~/.npm sudo rm -rf ~/.node-gyp sudo rm -rf /opt/local/bin/node sudo rm -rf opt/local/include/node sudo rm -rf /opt/local/lib/node_modules sudo rm -rf /usr/local/lib/node* sudo rm -rf /usr/local/include/node* sudo rm -rf /usr/local/bin/node* Go to home directory and remove any node or node_modules directory. You can verify your uninstallation by running these commands; they should not return any output. which node which nodejs which npm","title":"Setup of Production Server"},{"location":"production_setup/#objective","text":"The aim of this section is to set up a production server for deploying an application (DVNA) and solve the 3rd point of the Problem Statement under Task 1. About DVNA Damn Vulnerable NodeJS Application is a simple NodeJS application to demonstrate OWASP Top 10 Vulnerabilities and guide on fixing and avoiding these vulnerabilities. Prerequisites VM running Ubuntu 18.04 LTS. Docker installed","title":"Objective"},{"location":"production_setup/#step-1-install-docker","text":"For docker installation, I followed this documentation as its very simple and easy to execute. curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Alternatively, you can follow this official documentation for docker installation. First, Update the apt package index and install packages to allow apt to use a repository over HTTPS. sudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release Then add Docker\u2019s official GPG key. curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings docker-archive-keyring.gpg Use the following command to set up the stable repository. echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Update the apt package index, and install the latest version of Docker Engine and containerd (a daemon process that manages and runs containers). sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world # Test if docker installation is successful","title":"Step 1 - Install docker"},{"location":"production_setup/#step-2-setup-production-server","text":"I followed the official documentation available on GitHub to setup DVNA. DVNA interacts with a MySQL database. Store the db configuration in a file named vars.env . MYSQL_USER=dvna MYSQL_DATABASE=dvna MYSQL_PASSWORD=passw0rd MYSQL_RANDOM_ROOT_PASSWORD=yes MYSQL_HOST=mysql-db MYSQL_PORT=3306 Start MySQL container (using environment variables in vars.env file). Run an infinite command in detached mode (using -d ), so the command never ends and the container never stops. I used tail -f /dev/null because it is quite light weight and /dev/null is present in most linux images. sudo docker run -d --name dvna-mysql --env-file vars.env mysql:5.7 tail -f /dev/null Start/run the DVNA application. sudo docker run --name dvna-app --env-file vars.env --link dvna-mysql:mysql-db -p 9090:9090 -d appsecco/dvna To test if the containers are running, run a docker ps . You should see two containers running; dvna-app and dvna-mysql. You can stop running containers by using docker stop <container-name-or-id> . For deploying DVNA using Jenkins pipeline, the application will first be run in a docker container in the Jenkins VM. Static and dynamic analysis will be done and only then, will the application be deployed in the production server. Note: You can start the containers again using docker start <container-name-or-id> . When starting, however, you will have to start dvna-mysql container first because dvna-app is dependant on it. The docker commands can only be run as sudo user. There are 2 ways to enable executing docker commands without sudo. Although, you must know, its highly discouraged to do so. (i) Add 'user' to group 'docker' by typing the following command. The changes might not take effect without rebooting your VM. sudo usermod -aG docker $USER sudo reboot (ii) This method should only be used if no other method seems to work, since it grants every user permission to execute and run docker containers. sudo chmod 666 /var/run/docker.sock Follow these steps to completely uninstall/remove nodejs and npm from your VM. Removing Nodejs and Npm using apt package manager. sudo apt-get remove nodejs npm node sudo apt-get purge nodejs Now manually remove .node and .npm folders from your VM. sudo rm -rf /usr/local/bin/npm sudo rm -rf /usr/local/share/man/man1/node* sudo rm -rf /usr/local/lib/dtrace/node.d sudo rm -rf ~/.npm sudo rm -rf ~/.node-gyp sudo rm -rf /opt/local/bin/node sudo rm -rf opt/local/include/node sudo rm -rf /opt/local/lib/node_modules sudo rm -rf /usr/local/lib/node* sudo rm -rf /usr/local/include/node* sudo rm -rf /usr/local/bin/node* Go to home directory and remove any node or node_modules directory. You can verify your uninstallation by running these commands; they should not return any output. which node which nodejs which npm","title":"Step 2 - Setup Production Server"},{"location":"resources/","text":"These are some references I used along with the ones mentioned implicitly in the report: Setup of VMs Ubuntu ( https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04 ) OpenJDK ( https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04#installing-specific-versions-of-openjdk ) VM Network ( https://christophermaier.name/2010/09/01/host-only-networking-with-virtualbox/ ) Netplan ( https://www.linux.com/topic/distributions/how-use-netplan-network-configuration-tool-linux/ ) Setup of Jenkins Server Jenkins Installation ( https://www.digitalocean.com/community/tutorials/how-to-install-jenkins-on-ubuntu-18-04 ) Setup of Production Server DVNA ( https://github.com/appsecco/dvna ) Docker Installation ( https://docs.docker.com/engine/install/ubuntu/ ) Link Docker Containers ( https://docs.docker.com/network/links/ ) Static Analysis NPM Installation ( https://www.tecmint.com/install-nodejs-npm-in-centos-ubuntu/ ) NodeJsScan ( https://github.com/ajinabraham/nodejsscan ) Auditjs ( https://github.com/sonatype-nexus-community/auditjs ) Software Composition Analysis OWASP Dependancy Check ( https://owasp.org/www-project-dependency-check/ ) Dynamic Analysis ZAP docker ( https://www.zaproxy.org/docs/docker/about/ ) ZAP docker full-scan ( https://www.zaproxy.org/docs/docker/full-scan/ ) ZAP docker baseline-scan ( https://www.zaproxy.org/docs/docker/baseline-scan/ ) ZAP CLI ( https://github.com/Grunny/zap-cli ) Increase VM Disk Space ( https://ourcodeworld.com/articles/read/1434/how-to-increase-the-disk-size-of-a-dynamically-allocated-disk-in-virtualbox ) Software Code Quality Analysis JSHint ( https://jshint.com/docs/cli/ , https://github.com/jshint/jshint ) ESLint ( https://eslint.org/docs/user-guide/ , https://github.com/eslint/eslint ) ESLint CLI ( https://eslint.org/docs/user-guide/command-line-interface ) Shifting Local Setup to AWS EC2 Instances ( https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html ) Setup to use EC2 ( https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html#sign-up-for-aws )","title":"Resources"},{"location":"resources/#setup-of-vms","text":"Ubuntu ( https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-18-04 ) OpenJDK ( https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-18-04#installing-specific-versions-of-openjdk ) VM Network ( https://christophermaier.name/2010/09/01/host-only-networking-with-virtualbox/ ) Netplan ( https://www.linux.com/topic/distributions/how-use-netplan-network-configuration-tool-linux/ )","title":"Setup of VMs"},{"location":"resources/#setup-of-jenkins-server","text":"Jenkins Installation ( https://www.digitalocean.com/community/tutorials/how-to-install-jenkins-on-ubuntu-18-04 )","title":"Setup of Jenkins Server"},{"location":"resources/#setup-of-production-server","text":"DVNA ( https://github.com/appsecco/dvna ) Docker Installation ( https://docs.docker.com/engine/install/ubuntu/ ) Link Docker Containers ( https://docs.docker.com/network/links/ )","title":"Setup of Production Server"},{"location":"resources/#static-analysis","text":"NPM Installation ( https://www.tecmint.com/install-nodejs-npm-in-centos-ubuntu/ ) NodeJsScan ( https://github.com/ajinabraham/nodejsscan ) Auditjs ( https://github.com/sonatype-nexus-community/auditjs )","title":"Static Analysis"},{"location":"resources/#software-composition-analysis","text":"OWASP Dependancy Check ( https://owasp.org/www-project-dependency-check/ )","title":"Software Composition Analysis"},{"location":"resources/#dynamic-analysis","text":"ZAP docker ( https://www.zaproxy.org/docs/docker/about/ ) ZAP docker full-scan ( https://www.zaproxy.org/docs/docker/full-scan/ ) ZAP docker baseline-scan ( https://www.zaproxy.org/docs/docker/baseline-scan/ ) ZAP CLI ( https://github.com/Grunny/zap-cli ) Increase VM Disk Space ( https://ourcodeworld.com/articles/read/1434/how-to-increase-the-disk-size-of-a-dynamically-allocated-disk-in-virtualbox )","title":"Dynamic Analysis"},{"location":"resources/#software-code-quality-analysis","text":"JSHint ( https://jshint.com/docs/cli/ , https://github.com/jshint/jshint ) ESLint ( https://eslint.org/docs/user-guide/ , https://github.com/eslint/eslint ) ESLint CLI ( https://eslint.org/docs/user-guide/command-line-interface )","title":"Software Code Quality Analysis"},{"location":"resources/#shifting-local-setup-to-aws","text":"EC2 Instances ( https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html ) Setup to use EC2 ( https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html#sign-up-for-aws )","title":"Shifting Local Setup to AWS"},{"location":"sbom/","text":"Objective The aim of this section is to generate a Software Bill of Materials (SBoM) for DVNA and generate a report and solve the 7th point of the Problem Statement under Task 1. SBoM A Software Bill of Materials (SBOM) is a list of all the open source and third-party components present in a codebase. It lists the licenses that govern those components, the versions of the components used in the codebase, and their patch status. CycloneDX The CycloneDX module for Node.js creates a valid CycloneDX SBoM containing an aggregate of all project dependencies. It's a lightweight SBoM specification that is easily created, human and machine readable, and simple to parse. It also comes in a variety of implementations to serve projects using different stacks such as Python, Maven, .NET, etc. For my use case, I stuck with the NPM package as DVNA only utilizes Nodejs. Generating SBoM for DVNA Following the official documentation , I installed CycloneDX using NPM. npm install -g @cyclonedx/bom To generate a SBoM report, use the -o flag and specify the filename and its format. The report can be either XML or JSON. cyclonedx-bom -o sbom.xml SBoM Pipeline Add the following stage in the Jenkins pipeline for generating the SBoM. stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } }","title":"Software Bill of Materials"},{"location":"sbom/#objective","text":"The aim of this section is to generate a Software Bill of Materials (SBoM) for DVNA and generate a report and solve the 7th point of the Problem Statement under Task 1.","title":"Objective"},{"location":"sbom/#sbom","text":"A Software Bill of Materials (SBOM) is a list of all the open source and third-party components present in a codebase. It lists the licenses that govern those components, the versions of the components used in the codebase, and their patch status.","title":"SBoM"},{"location":"sbom/#cyclonedx","text":"The CycloneDX module for Node.js creates a valid CycloneDX SBoM containing an aggregate of all project dependencies. It's a lightweight SBoM specification that is easily created, human and machine readable, and simple to parse. It also comes in a variety of implementations to serve projects using different stacks such as Python, Maven, .NET, etc. For my use case, I stuck with the NPM package as DVNA only utilizes Nodejs.","title":"CycloneDX"},{"location":"sbom/#generating-sbom-for-dvna","text":"Following the official documentation , I installed CycloneDX using NPM. npm install -g @cyclonedx/bom To generate a SBoM report, use the -o flag and specify the filename and its format. The report can be either XML or JSON. cyclonedx-bom -o sbom.xml","title":"Generating SBoM for DVNA"},{"location":"sbom/#sbom-pipeline","text":"Add the following stage in the Jenkins pipeline for generating the SBoM. stage ('Generating Software Bill of Materials') { steps { sh 'cd ~/app && cyclonedx-bom -o ~/reports/sbom.xml' } }","title":"SBoM Pipeline"},{"location":"sca/","text":"Objective The aim of this section is to explain the software composition of DVNA using SCA tools in a Jenkins pipeline and solve the 5th point of the Problem Statement under Task 1. Prerequisites An application (DVNA) running on Production Server. SCA Software composition analysis (SCA) identifies all the open source in a codebase and maps that inventory to a list of current known vulnerabilities. It helps identify vulnerabilities in open source code (dependencies) used in code. OWASP Dependancy-Check OWASP Dependency-Check is a software composition analysis (SCA) tool that detects publicly disclosed vulnerabilities contained within a project\u2019s dependencies. It does this by determining if there is a Common Platform Enumeration (CPE) identifier for a given dependency. If found, it will generate a report linking to the associated CVE entries. Performing SCA on DVNA To start working with Dependency Check, I followed the official documentation . First, download the Dependency-Check CLI tool and the associated GPG signature file. wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip.asc Next, extract the files from the dependency-check tool zip file. unzip ~/dependency-check-6.2.2-release.zip Perform the scan by specifying the path to the project, output report format and its location. ~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/report/dependency-check-report --format JSON --prettyPrint Note : This scan is inclusive of Retire.js scan, NPM Audit scan, and Auditjs scan, to name a few. SCA Pipeline Add the following stage in the Jenkins pipeline to perform SCA of DVNA. stage ('OWASP Dependency-Check') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } }","title":"Software Composition Analysis"},{"location":"sca/#objective","text":"The aim of this section is to explain the software composition of DVNA using SCA tools in a Jenkins pipeline and solve the 5th point of the Problem Statement under Task 1. Prerequisites An application (DVNA) running on Production Server.","title":"Objective"},{"location":"sca/#sca","text":"Software composition analysis (SCA) identifies all the open source in a codebase and maps that inventory to a list of current known vulnerabilities. It helps identify vulnerabilities in open source code (dependencies) used in code.","title":"SCA"},{"location":"sca/#owasp-dependancy-check","text":"OWASP Dependency-Check is a software composition analysis (SCA) tool that detects publicly disclosed vulnerabilities contained within a project\u2019s dependencies. It does this by determining if there is a Common Platform Enumeration (CPE) identifier for a given dependency. If found, it will generate a report linking to the associated CVE entries.","title":"OWASP Dependancy-Check"},{"location":"sca/#performing-sca-on-dvna","text":"To start working with Dependency Check, I followed the official documentation . First, download the Dependency-Check CLI tool and the associated GPG signature file. wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip wget -P ~/ https://github.com/jeremylong/DependencyCheck/releases/download/v6.2.2/dependency-check-6.2.2-release.zip.asc Next, extract the files from the dependency-check tool zip file. unzip ~/dependency-check-6.2.2-release.zip Perform the scan by specifying the path to the project, output report format and its location. ~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/report/dependency-check-report --format JSON --prettyPrint Note : This scan is inclusive of Retire.js scan, NPM Audit scan, and Auditjs scan, to name a few.","title":"Performing SCA on DVNA"},{"location":"sca/#sca-pipeline","text":"Add the following stage in the Jenkins pipeline to perform SCA of DVNA. stage ('OWASP Dependency-Check') { steps { sh '~/dependency-check/bin/dependency-check.sh --scan ~/app --out ~/reports/dependency-check-report --format JSON --prettyPrint || true' } }","title":"SCA Pipeline"},{"location":"scqa/","text":"Objective The aim of this section is to perform code linting and generate a code quality report and solve the 8th point of the Problem Statement under Task 1. Code Linting Code linting is the automated checking of your source code for programmatic and stylistic errors. It's great for identifying violations of standard rules and is the most basic form of static analysis. Lint tools (aka linters) help accelerate developement process and reduce costs by finding errors earlier. JSHint JSHint is a static code analysis tool that helps to detect errors and potential problems in your JavaScript code. It scans a program written in JavaScript and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to an implicit type conversion, a leaking variable, or something else entirely. To get started with JSHint, I followed this documentation . Since I'm performing a test on a NodeJs application (DVNA), I installed JSHint using NPM. npm install -g jshint Run the jshint command with the application/project directory to scan all .js files. To generate a report, we can either just redirect the output stream to a file or make use of reporters to create XML or JSON reports. jshint ~/app > ~/report/jshint-report The above command will scan all the files in the /app directory. To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report JSHint Pipeline stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f \\( -name \"*.js\" -o -name \"*.ejs\" \\) | grep -v node_modules) > ~/reports/jshint-report || true' } } ESLint ESLint is a tool for identifying and reporting on patterns found in ECMAScript/JavaScript code. Unlike JSHint, ESLint uses Espree for JavaScript parsing and an AST to evaluate patterns in code. It's completely pluggable, every single rule is a plugin and you can add more at runtime. To get started with JSHint, I followed the official documentation . Install eslint using NPM. npm install -g eslint To run the scan, eslint requires a .eslintrc configuration file which contains environment variables, rules and other config details. To create this file, navigate to your project folder and run eslint --init . You will be prompted to a few questions to create the config file. The questions and my responses to them are given below. \u2714 How would you like to use ESLint? \u00b7 problems \u2714 What type of modules does your project use? \u00b7 commonjs \u2714 Which framework does your project use? \u00b7 none \u2714 Does your project use TypeScript? \u00b7 No \u2714 Where does your code run? \u00b7 browser \u2714 What format do you want your config file to be in? \u00b7 JSON The contents of the new .eslintrc.json config file are: { \"env\": { \"browser\": true, \"commonjs\": true, \"es2021\": true }, \"extends\": \"eslint:recommended\", \"parserOptions\": { \"ecmaVersion\": 12 }, \"rules\": { } } Note: The .eslintrc.* config file is required everytime you want to run an eslint scan on a file or directory. While running the scans in a pipeline, its not possible to create the config file by running eslint --init as the command line waits for responses to file configuration questions. To work around this problem, copy the configuration details shown above into <Jenkins-Home-Dir>/.eslintrc.json file. You can now specify eslint to use this config file during its execution. To perform an eslint scan, run eslint command with the following flags; -c , specify the config file to use; -f , format of output report; --ext , specify the extensions of files to be scannned; -o , specify file to write report to eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app ESLint Pipeline stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } } Code Quality Pipeline Add the following stages in the Jenkins pipeline for performing code linting. stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f \\( -name \"*.js\" -o -name \"*.ejs\" \\) | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } }","title":"Software Code Quality Analysis"},{"location":"scqa/#objective","text":"The aim of this section is to perform code linting and generate a code quality report and solve the 8th point of the Problem Statement under Task 1.","title":"Objective"},{"location":"scqa/#code-linting","text":"Code linting is the automated checking of your source code for programmatic and stylistic errors. It's great for identifying violations of standard rules and is the most basic form of static analysis. Lint tools (aka linters) help accelerate developement process and reduce costs by finding errors earlier.","title":"Code Linting"},{"location":"scqa/#jshint","text":"JSHint is a static code analysis tool that helps to detect errors and potential problems in your JavaScript code. It scans a program written in JavaScript and reports about commonly made mistakes and potential bugs. The potential problem could be a syntax error, a bug due to an implicit type conversion, a leaking variable, or something else entirely. To get started with JSHint, I followed this documentation . Since I'm performing a test on a NodeJs application (DVNA), I installed JSHint using NPM. npm install -g jshint Run the jshint command with the application/project directory to scan all .js files. To generate a report, we can either just redirect the output stream to a file or make use of reporters to create XML or JSON reports. jshint ~/app > ~/report/jshint-report The above command will scan all the files in the /app directory. To restrict the scan to only .js and .ejs files, use a find command. We will further exclude all files in the node_modules directory. jshint $(find ~/app -type f -name \"*.js\" -o -name \"*.ejs\" | grep -v node_modules) > ~/reports/jshint-report JSHint Pipeline stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f \\( -name \"*.js\" -o -name \"*.ejs\" \\) | grep -v node_modules) > ~/reports/jshint-report || true' } }","title":"JSHint"},{"location":"scqa/#eslint","text":"ESLint is a tool for identifying and reporting on patterns found in ECMAScript/JavaScript code. Unlike JSHint, ESLint uses Espree for JavaScript parsing and an AST to evaluate patterns in code. It's completely pluggable, every single rule is a plugin and you can add more at runtime. To get started with JSHint, I followed the official documentation . Install eslint using NPM. npm install -g eslint To run the scan, eslint requires a .eslintrc configuration file which contains environment variables, rules and other config details. To create this file, navigate to your project folder and run eslint --init . You will be prompted to a few questions to create the config file. The questions and my responses to them are given below. \u2714 How would you like to use ESLint? \u00b7 problems \u2714 What type of modules does your project use? \u00b7 commonjs \u2714 Which framework does your project use? \u00b7 none \u2714 Does your project use TypeScript? \u00b7 No \u2714 Where does your code run? \u00b7 browser \u2714 What format do you want your config file to be in? \u00b7 JSON The contents of the new .eslintrc.json config file are: { \"env\": { \"browser\": true, \"commonjs\": true, \"es2021\": true }, \"extends\": \"eslint:recommended\", \"parserOptions\": { \"ecmaVersion\": 12 }, \"rules\": { } } Note: The .eslintrc.* config file is required everytime you want to run an eslint scan on a file or directory. While running the scans in a pipeline, its not possible to create the config file by running eslint --init as the command line waits for responses to file configuration questions. To work around this problem, copy the configuration details shown above into <Jenkins-Home-Dir>/.eslintrc.json file. You can now specify eslint to use this config file during its execution. To perform an eslint scan, run eslint command with the following flags; -c , specify the config file to use; -f , format of output report; --ext , specify the extensions of files to be scannned; -o , specify file to write report to eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app ESLint Pipeline stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } }","title":"ESLint"},{"location":"scqa/#code-quality-pipeline","text":"Add the following stages in the Jenkins pipeline for performing code linting. stage ('JSHint Analysis') { steps { sh 'jshint $(find ~/app -type f \\( -name \"*.js\" -o -name \"*.ejs\" \\) | grep -v node_modules) > ~/reports/jshint-report || true' } } stage ('ESLint Analysis') { steps { sh 'eslint -c ~/.eslintrc.json -f html --ext .js,.ejs -o ~/reports/eslint-report.html ~/app || true' } }","title":"Code Quality Pipeline"},{"location":"ssh_connection/","text":"Objective The aim of this section is to enable SSH communication between the two VMs as part of the solution to 1st point of the Problem Statement under Task 1. About SSH SSH provides a secure encrypted channel between two hosts over an insecure network. This connection can also be used for terminal access, file transfers, and for tunneling other applications. It uses public/private key pair. The public key can be given to everyone. The private key is kept secret and used to authenticate the user trying to establish a connection. Prerequisites VMs running Ubuntu 18.04 LTS. Generating SSH Keys Generate SSH keys in the Jenkins VM using ssh-keygen . The encryption algorithm I used is ed25519, which is generally much faster than RSA and provides the same level of security with significantly smaller keys. Consequently, two files are generated; id_ed25519 and id_ed25519.pub. The former contains the private key, while the public key is present in the latter. ssh-keygen -t ed25519 -m PEM You will be prompted to add a passphrase. You can either provide one or leave it empty. Copying SSH Key Copy the public key from Jenkins server (id_ed25519.pub) into .ssh/authorized_users file of Production servers. ssh-copy-id -i ~/.ssh/id_ed25519 <username>@<production_server_ip> Copy the .ssh folder in Jenkins server into /var/lib/jenkins of the same server and change the ownership of the folder from root to jenkins. This is because jenkins user executes commands. Also, change the permissions of the /var/lib/jenkins/.ssh to only-read mode for owner (ie. user jenkins ) sudo cp -r ~/.ssh /var/lib/jenkins sudo chown -R jenkins:jenkins /var/lib/jenkins/.ssh sudo chmod 400 /var/lib/jenkins/.ssh Test SSH Connection Use ssh command to successfully login to the other server without being prompted for a password. Test SSH connection as user jenkins . sudo su - jenkins ssh <username>@<ip_address_of_server> Jenkins remote SSH Install Publish over SSH plugin. Go to Dashboard \u2192 Manage Jenkins \u2192 Configure System \u2192 Publish over SSH . Add the path to the private SSH key of Jenkins server or copy the private SSH key into the input field. Add SSH server details. Give the Production servers hostname (IP address), username for logging in and remote directory (/home/tariq). You should now be able to run remote SSH commands via Jenkins pipeline.","title":"SSH Connection between VMs"},{"location":"ssh_connection/#objective","text":"The aim of this section is to enable SSH communication between the two VMs as part of the solution to 1st point of the Problem Statement under Task 1. About SSH SSH provides a secure encrypted channel between two hosts over an insecure network. This connection can also be used for terminal access, file transfers, and for tunneling other applications. It uses public/private key pair. The public key can be given to everyone. The private key is kept secret and used to authenticate the user trying to establish a connection. Prerequisites VMs running Ubuntu 18.04 LTS.","title":"Objective"},{"location":"ssh_connection/#generating-ssh-keys","text":"Generate SSH keys in the Jenkins VM using ssh-keygen . The encryption algorithm I used is ed25519, which is generally much faster than RSA and provides the same level of security with significantly smaller keys. Consequently, two files are generated; id_ed25519 and id_ed25519.pub. The former contains the private key, while the public key is present in the latter. ssh-keygen -t ed25519 -m PEM You will be prompted to add a passphrase. You can either provide one or leave it empty.","title":"Generating SSH Keys"},{"location":"ssh_connection/#copying-ssh-key","text":"Copy the public key from Jenkins server (id_ed25519.pub) into .ssh/authorized_users file of Production servers. ssh-copy-id -i ~/.ssh/id_ed25519 <username>@<production_server_ip> Copy the .ssh folder in Jenkins server into /var/lib/jenkins of the same server and change the ownership of the folder from root to jenkins. This is because jenkins user executes commands. Also, change the permissions of the /var/lib/jenkins/.ssh to only-read mode for owner (ie. user jenkins ) sudo cp -r ~/.ssh /var/lib/jenkins sudo chown -R jenkins:jenkins /var/lib/jenkins/.ssh sudo chmod 400 /var/lib/jenkins/.ssh","title":"Copying SSH Key"},{"location":"ssh_connection/#test-ssh-connection","text":"Use ssh command to successfully login to the other server without being prompted for a password. Test SSH connection as user jenkins . sudo su - jenkins ssh <username>@<ip_address_of_server>","title":"Test SSH Connection"},{"location":"ssh_connection/#jenkins-remote-ssh","text":"Install Publish over SSH plugin. Go to Dashboard \u2192 Manage Jenkins \u2192 Configure System \u2192 Publish over SSH . Add the path to the private SSH key of Jenkins server or copy the private SSH key into the input field. Add SSH server details. Give the Production servers hostname (IP address), username for logging in and remote directory (/home/tariq). You should now be able to run remote SSH commands via Jenkins pipeline.","title":"Jenkins remote SSH"},{"location":"static_analysis/","text":"Objective The aim of this section is to perform static analysis on DVNA using SAST tools in a Jenkins pipeline and solve the 4th point of the Problem Statement under Task 1. About SAST Static application security testing (SAST) is a testing methodology that analyzes source code to find security vulnerabilities. SAST scans an application before the code is compiled. Since the test is performed on the source code, ie. the internal structures or workings of an application, and not its functionality, its also called white box testing. Prerequisites An application (DVNA) running on Production Server. NodeJsScan NodeJsScan is a static code scanner which is used to find security flaws in Node.js applications. In the Jenkins server, enter DVNA container in exec mode. sudo docker exec -it -u 0 dvna-app /bin/bash Following the official documentation available on GitHub, I installed njsscan using pip3. To use pip3, we first need to install it in the dvna-app container in production server. apt update && apt install python3-pip Install njsscan using pip3. pip3 install njsscan Scan the ~/app directory (which holds the files for DVNA) and store the scan result in ~/reports/nodejsscan-report mkdir ~/reports njsscan --json -o /app/reports/nodejsscan-report ~/app NodeJsScan Pipeline stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } Auditjs Auditjs is a SAST tool which detects vulnerablilites in dependencies (node modules) used in your application. It interacts with Sonatype Nexus IQ Server to check for known and disclosed vulnerabailites. In the Jenkins server, enter DVNA container in exec mode. sudo docker exec -it -u 0 dvna-app /bin/bash Following the official documentation available on GitHub, I installed auditjs using NPM (Node Packet Manager). To install npm and nodejs in dvna-app container in production server, I referred this documentation as it's clear and easy to follow. After running the following commands, the package versions are: npm v6.14.14 and nodejs v14.17.4 . Note: Installing nodejs from deb.nodesource.com comes with a prepackaged NPM. So you don't need to install npm using the apt package manager. Additionally, to update npm to latest version, use sudo npm install latest-version after running the commands below. sudo apt update sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt install -y nodejs Install auditjs using npm. sudo npm install -g auditjs Scan the ~/app directory (which holds the files for DVNA) and store the scan result in ~/reports/auditjs-report . cd ~/app auditjs ossi > ~/reports/auditjs-report If your NodeJs project is very large, you might face rate-limit issues. To solve this issue, create a free account at OSS Index and run the scan with your accounts username and API-token . Note : You can find the API-token in the User Settings after logging into the OSS Index website. auditjs ossi --username <USERNAME> --token <API-TOKEN> > ~/reports/auditjs-report AuditJs Pipeline stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } } SAST Pipeline The static analysis is done on the application source code in dvna-app container running on Jenkins server. Add the following stages to the Jenkinsfile for performing SAST of DVNA. stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } }","title":"Static Analysis"},{"location":"static_analysis/#objective","text":"The aim of this section is to perform static analysis on DVNA using SAST tools in a Jenkins pipeline and solve the 4th point of the Problem Statement under Task 1. About SAST Static application security testing (SAST) is a testing methodology that analyzes source code to find security vulnerabilities. SAST scans an application before the code is compiled. Since the test is performed on the source code, ie. the internal structures or workings of an application, and not its functionality, its also called white box testing. Prerequisites An application (DVNA) running on Production Server.","title":"Objective"},{"location":"static_analysis/#nodejsscan","text":"NodeJsScan is a static code scanner which is used to find security flaws in Node.js applications. In the Jenkins server, enter DVNA container in exec mode. sudo docker exec -it -u 0 dvna-app /bin/bash Following the official documentation available on GitHub, I installed njsscan using pip3. To use pip3, we first need to install it in the dvna-app container in production server. apt update && apt install python3-pip Install njsscan using pip3. pip3 install njsscan Scan the ~/app directory (which holds the files for DVNA) and store the scan result in ~/reports/nodejsscan-report mkdir ~/reports njsscan --json -o /app/reports/nodejsscan-report ~/app NodeJsScan Pipeline stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } }","title":"NodeJsScan"},{"location":"static_analysis/#auditjs","text":"Auditjs is a SAST tool which detects vulnerablilites in dependencies (node modules) used in your application. It interacts with Sonatype Nexus IQ Server to check for known and disclosed vulnerabailites. In the Jenkins server, enter DVNA container in exec mode. sudo docker exec -it -u 0 dvna-app /bin/bash Following the official documentation available on GitHub, I installed auditjs using NPM (Node Packet Manager). To install npm and nodejs in dvna-app container in production server, I referred this documentation as it's clear and easy to follow. After running the following commands, the package versions are: npm v6.14.14 and nodejs v14.17.4 . Note: Installing nodejs from deb.nodesource.com comes with a prepackaged NPM. So you don't need to install npm using the apt package manager. Additionally, to update npm to latest version, use sudo npm install latest-version after running the commands below. sudo apt update sudo curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt install -y nodejs Install auditjs using npm. sudo npm install -g auditjs Scan the ~/app directory (which holds the files for DVNA) and store the scan result in ~/reports/auditjs-report . cd ~/app auditjs ossi > ~/reports/auditjs-report If your NodeJs project is very large, you might face rate-limit issues. To solve this issue, create a free account at OSS Index and run the scan with your accounts username and API-token . Note : You can find the API-token in the User Settings after logging into the OSS Index website. auditjs ossi --username <USERNAME> --token <API-TOKEN> > ~/reports/auditjs-report AuditJs Pipeline stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } }","title":"Auditjs"},{"location":"static_analysis/#sast-pipeline","text":"The static analysis is done on the application source code in dvna-app container running on Jenkins server. Add the following stages to the Jenkinsfile for performing SAST of DVNA. stage('NodeJsScan') { steps { sh 'njsscan --json -o ~/reports/nodejsscan-report ~/app || true' } } stage('Auditjs') { steps { sh 'cd ~/app; auditjs ossi > ~/reports/auditjs-report || true' } }","title":"SAST Pipeline"},{"location":"vm_setup/","text":"Objective The aim of this section is to set up VMs running Ubuntu Server and solve the 1st point of the Problem Statement under Task 1. Setting up VMs For the lab setup, create 2 VMs running Ubuntu 18.04 LTS on VirtualBox. One VM is for Jenkins deployment and the other is a production server for deploying DVNA via Jenkins pipeline. I followed this documentation upto Up and Running with SSH step, for installing Ubuntu on both the VMs. In the blog, they used a Bridged connection for enabling VM-to-VM and host-to-VM communication. Although this connection was initially working fine, the connectivity between the two VMs would very often get dropped for a couple of minutes. So to solve this issue, I instead used 2 adaptors; one for NAT and the other a Host-only network. VM Network Configuration Open Virtual Box and go to File -> Host Network Manager . The Host Network Manager window will open, and ideally, a network named \"vboxnet0\" should exist with the DHCP server disabled. If it does not exist, you can create it by clicking on the \"Create\" button. The new network created will be named \"vboxnet0\" and ensure DHCP server is not enabled. This network will enable host-to-VM communication. Now, open the Oracle VM VirtualBox Manager , click on the VM that you wish to configure for networking and go to the Network group. Follow this configuration steps for both the VMs (Jenkins and Production VMs, in my case). Adaptor 1 -> Click on Enable Network Adapter and in the Attached field, select NAT. Adaptor 2 -> Click on Enable Network Adapter and make sure the fields are configured like this: Attached to - Host-only Adapter, Name - vboxnet0. We need each of the guest VMs to have a static IP address on the host-only network. Log in to your Ubuntu guest and type the following command. ifconfig <interface> 192.168.56.101 netmask 255.255.255.0 up Now you should be able to SSH into your VM from your host using this IP address. This is just temporary, however; once you reboot, this configuration will disappear. To make it permanent, add this to the .yml file in /etc/netplan directory (as root ): # This is the network config written by 'subiquity' network: ethernets: enp0s3: dhcp4: true enp0s8: addresses: [192.168.56.101/24] nameservers: addresses: [1.1.1.1,8.8.8.8] version: 2 Before we apply the change, let\u2019s test the configuration. To do that, issue the command: sudo netplan try The above command will validate the configuration before applying it. If it succeeds, you will see Configuration accepted and Netplan will attempt to apply the new settings to a running system. Should the new configuration file fail, Netplan will automatically revert to the previous working configuration. If you are certain of your configuration file, you can skip the try option and go directly to applying the new options. The command for this is: sudo netplan apply Your setup should now be complete! Note: Fix for updating apt package repository After installing Ubuntu 18.04 LTS iso file and running two VMs using it, I tried to update all packages and their dependancies using sudo apt install update . This, however, was not working and threw errors. As my location was Kuwait, it tried reaching out to https://kw.archive.ubuntu.com/ ..._ to find updates. But this archive server was not reachable. To solve this issue, I changed all occurences of https://kw.archive.ubuntu.com/ ... to https://archive.ubuntu.com/ ... in the sources.list file sudo nano /etc/apt/sources.list Your VM should now be able to interact with the ubuntu archive server for updates and other packages.","title":"Setup of VMs"},{"location":"vm_setup/#objective","text":"The aim of this section is to set up VMs running Ubuntu Server and solve the 1st point of the Problem Statement under Task 1.","title":"Objective"},{"location":"vm_setup/#setting-up-vms","text":"For the lab setup, create 2 VMs running Ubuntu 18.04 LTS on VirtualBox. One VM is for Jenkins deployment and the other is a production server for deploying DVNA via Jenkins pipeline. I followed this documentation upto Up and Running with SSH step, for installing Ubuntu on both the VMs. In the blog, they used a Bridged connection for enabling VM-to-VM and host-to-VM communication. Although this connection was initially working fine, the connectivity between the two VMs would very often get dropped for a couple of minutes. So to solve this issue, I instead used 2 adaptors; one for NAT and the other a Host-only network.","title":"Setting up VMs"},{"location":"vm_setup/#vm-network-configuration","text":"Open Virtual Box and go to File -> Host Network Manager . The Host Network Manager window will open, and ideally, a network named \"vboxnet0\" should exist with the DHCP server disabled. If it does not exist, you can create it by clicking on the \"Create\" button. The new network created will be named \"vboxnet0\" and ensure DHCP server is not enabled. This network will enable host-to-VM communication. Now, open the Oracle VM VirtualBox Manager , click on the VM that you wish to configure for networking and go to the Network group. Follow this configuration steps for both the VMs (Jenkins and Production VMs, in my case). Adaptor 1 -> Click on Enable Network Adapter and in the Attached field, select NAT. Adaptor 2 -> Click on Enable Network Adapter and make sure the fields are configured like this: Attached to - Host-only Adapter, Name - vboxnet0. We need each of the guest VMs to have a static IP address on the host-only network. Log in to your Ubuntu guest and type the following command. ifconfig <interface> 192.168.56.101 netmask 255.255.255.0 up Now you should be able to SSH into your VM from your host using this IP address. This is just temporary, however; once you reboot, this configuration will disappear. To make it permanent, add this to the .yml file in /etc/netplan directory (as root ): # This is the network config written by 'subiquity' network: ethernets: enp0s3: dhcp4: true enp0s8: addresses: [192.168.56.101/24] nameservers: addresses: [1.1.1.1,8.8.8.8] version: 2 Before we apply the change, let\u2019s test the configuration. To do that, issue the command: sudo netplan try The above command will validate the configuration before applying it. If it succeeds, you will see Configuration accepted and Netplan will attempt to apply the new settings to a running system. Should the new configuration file fail, Netplan will automatically revert to the previous working configuration. If you are certain of your configuration file, you can skip the try option and go directly to applying the new options. The command for this is: sudo netplan apply Your setup should now be complete! Note: Fix for updating apt package repository After installing Ubuntu 18.04 LTS iso file and running two VMs using it, I tried to update all packages and their dependancies using sudo apt install update . This, however, was not working and threw errors. As my location was Kuwait, it tried reaching out to https://kw.archive.ubuntu.com/ ..._ to find updates. But this archive server was not reachable. To solve this issue, I changed all occurences of https://kw.archive.ubuntu.com/ ... to https://archive.ubuntu.com/ ... in the sources.list file sudo nano /etc/apt/sources.list Your VM should now be able to interact with the ubuntu archive server for updates and other packages.","title":"VM Network Configuration"},{"location":"working_of_pipeline/","text":"Objective The aim of this section is to understand the Jenkins pipeline to deploy DVNA and solve the points 2-8 in Problem Statement under Task 1. Jenkins Pipeline Jenkins is a continuous integration server which has the ability to support the automation of software development processes. It can be used to create several automation jobs and run them as a pipeline. Jenkins pipelines are made up of multiple stages (jobs/events) that allow you to build, test and deploy applications. Every stage has some sort of dependency on at least one or more stages in a pipeline. In DevSecOps, security is integrated into the pipeline by performing static and dynamic analysis using various SAST and DAST tools. To start creating a new pipeline in Jenkins, login to the Jenkins web interface by typing jenkins_server_ip:8080 in the url. Follow the steps below: On the left hand side of the Dashboard page, click New Item to create a new project or pipeline. Provide a name for your pipeline (say DVNA_pipeline ), select Pipeline as the project type and click OK . You will then be redirected to the Configure page for your newly created project. Under the General section- Check the Discard Old Builds option if you don't want to keep the console output, archived artifacts, and any other metadata related to older builds. They take up unnecessary disk space on the server. You can then specify the max number of days to keep builds and how many builds at max should be kept. Under the Pipeline section- Select Pipeline script from SCM and the SCM as Git . You will then have to specify your GitHub URL where your file containing details about the pipeline (aka Jenkinsfile) resides. There is an option to specify the Git branch and Jenkinsfile location in the repository. Note: GitHub has deprecated the use of username and passwords for cloning Git repositories. You must instead use access tokens, which you can create from your GitHub account settings. The URL format should be like this- https://<access_token>@github.com/<github_username>/<repo> Click Save to save and apply the configurations. To initiate build, Go to Dashboard -> DVNA_Pipeline -> Build Now . Jenkinsfile A Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline. pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=<PASSWORD> MYSQL_RANDOM_ROOT_PASSWORD=<ROOT_PASSWORD> MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/ && mkdir ~/reports && chmod 777 ~/reports' } } stage('SAST and DAST Scans') { ........ } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna && docker rmi mysql:5.7' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env tariq@192.168.56.102:~/' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } } Components of the Jenkinsfile- pipeline - Constitutes the entire definition of the pipeline. agent - Used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. stages - Consists of all the stages/jobs to be performed during the execution of the pipeline. stage - Specify the task to be performed. steps - Defines actions to be performed within a particular stage. sh - Used to execute shell commands. CI/CD Pipeline for Deploying DVNA The pipeline is divided into various stages based on the operations being performed. They are as follows: Initialization This is the first stage in the pipeline and is used just to indicate the start of the build. Build In this stage, vars.env file is created as it contains the environment variables for dvna-mysql db container. Two containers, dvna-app and dvna-mysql , are then run and the application code is copied into the hosts jenkins home directory (in my case, /var/lib/jenkins ). SAST and DAST Scans All the stages following the Build stage, excluding the last two stages, are for performing SAST and DAST on the application. The scans are performed on the application running on the Jenkins VM and their output reports are stored in a folder named reports in jenkins home directory. Note: Most of the scans such as like NodeJsScan, AuditJs, JSHint, etc. return a non-zero exit code, even on successful completion. Jenkins considers non-zero status code as FAILED and stops the build. To overcome this, you can add either of the following at the end of the scan commands to give a 0 status code. <scan command> || true OR <scan command>; echo $? > /dev/null Remove DVNA from Jenkins After the scans are complete, the containers running in Jenkins VM are stopped and removed. Since we're working with a containerized application (DVNA), we need to perform tests on the latest available image on DockerHub. Hence, we remove the existing local appsecco/dvna docker image to avoid running a container with older release of the application image. On the other hand, you don't need to remove the mysql:5.7 image, since we require v5.7 and not the latest version. Deploy DVNA to Production Finally, operations are performed on the Production VM over SSH (configured in the section titled SSH Connection Between VMs ). vars.env file is copied into Production server, and the two containers; dvna-app and dvna-mysql , are run. The application is now successfully deployed!","title":"Working of Pipeline"},{"location":"working_of_pipeline/#objective","text":"The aim of this section is to understand the Jenkins pipeline to deploy DVNA and solve the points 2-8 in Problem Statement under Task 1.","title":"Objective"},{"location":"working_of_pipeline/#jenkins-pipeline","text":"Jenkins is a continuous integration server which has the ability to support the automation of software development processes. It can be used to create several automation jobs and run them as a pipeline. Jenkins pipelines are made up of multiple stages (jobs/events) that allow you to build, test and deploy applications. Every stage has some sort of dependency on at least one or more stages in a pipeline. In DevSecOps, security is integrated into the pipeline by performing static and dynamic analysis using various SAST and DAST tools. To start creating a new pipeline in Jenkins, login to the Jenkins web interface by typing jenkins_server_ip:8080 in the url. Follow the steps below: On the left hand side of the Dashboard page, click New Item to create a new project or pipeline. Provide a name for your pipeline (say DVNA_pipeline ), select Pipeline as the project type and click OK . You will then be redirected to the Configure page for your newly created project. Under the General section- Check the Discard Old Builds option if you don't want to keep the console output, archived artifacts, and any other metadata related to older builds. They take up unnecessary disk space on the server. You can then specify the max number of days to keep builds and how many builds at max should be kept. Under the Pipeline section- Select Pipeline script from SCM and the SCM as Git . You will then have to specify your GitHub URL where your file containing details about the pipeline (aka Jenkinsfile) resides. There is an option to specify the Git branch and Jenkinsfile location in the repository. Note: GitHub has deprecated the use of username and passwords for cloning Git repositories. You must instead use access tokens, which you can create from your GitHub account settings. The URL format should be like this- https://<access_token>@github.com/<github_username>/<repo> Click Save to save and apply the configurations. To initiate build, Go to Dashboard -> DVNA_Pipeline -> Build Now .","title":"Jenkins Pipeline"},{"location":"working_of_pipeline/#jenkinsfile","text":"A Jenkinsfile is a text file that contains the definition of a Jenkins Pipeline. pipeline { agent any stages { stage ('Initialization') { steps { sh 'echo \"Starting the build!\"' } } stage ('Build') { environment { MYSQL_USER=\"dvna\" MYSQL_DATABASE=\"dvna\" MYSQL_PASSWORD=<PASSWORD> MYSQL_RANDOM_ROOT_PASSWORD=<ROOT_PASSWORD> MYSQL_HOST=\"mysql-db\" MYSQL_PORT=3306 } steps { sh 'echo \"MYSQL_USER=$MYSQL_USER\\nMYSQL_DATABASE=$MYSQL_DATABASE\\nMYSQL_PASSWORD=$MYSQL_PASSWORD\\nMYSQL_RANDOM_ROOT_PASSWORD=$MYSQL_RANDOM_ROOT_PASSWORD\\nMYSQL_HOST=$MYSQL_HOST\\nMYSQL_PORT=$MYSQL_PORT\" > ~/vars.env' sh 'docker run --rm -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null' sh 'docker run --rm -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna' sh 'docker cp dvna-app:/app/ ~/ && mkdir ~/reports && chmod 777 ~/reports' } } stage('SAST and DAST Scans') { ........ } stage ('Remove DVNA from Jenkins') { steps { sh 'rm -rf ~/app' sh 'docker stop dvna-app && docker stop dvna-mysql' sh 'docker rmi appsecco/dvna && docker rmi mysql:5.7' } } stage ('Deploy DVNA to Production') { steps { sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker stop dvna-app && docker stop dvna-mysql && docker rm dvna-app && docker rm dvna-mysql && docker rmi appsecco/dvna || true\"' sh 'scp ~/vars.env tariq@192.168.56.102:~/' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-mysql --env-file ~/vars.env mysql:5.7 tail -f /dev/null\"' sh 'ssh -o StrictHostKeyChecking=no tariq@192.168.56.102 \"docker run -d --name dvna-app --env-file ~/vars.env --link dvna-mysql:mysql-db -p 9090:9090 appsecco/dvna\"' } } } } Components of the Jenkinsfile- pipeline - Constitutes the entire definition of the pipeline. agent - Used to choose the way the Jenkins instance(s) are used to run the pipeline. The any keyword defines that Jenkins should allocate any available agent (an instance of Jenkins/a slave/the master instance) to execute the pipeline. stages - Consists of all the stages/jobs to be performed during the execution of the pipeline. stage - Specify the task to be performed. steps - Defines actions to be performed within a particular stage. sh - Used to execute shell commands.","title":"Jenkinsfile"},{"location":"working_of_pipeline/#cicd-pipeline-for-deploying-dvna","text":"The pipeline is divided into various stages based on the operations being performed. They are as follows: Initialization This is the first stage in the pipeline and is used just to indicate the start of the build. Build In this stage, vars.env file is created as it contains the environment variables for dvna-mysql db container. Two containers, dvna-app and dvna-mysql , are then run and the application code is copied into the hosts jenkins home directory (in my case, /var/lib/jenkins ). SAST and DAST Scans All the stages following the Build stage, excluding the last two stages, are for performing SAST and DAST on the application. The scans are performed on the application running on the Jenkins VM and their output reports are stored in a folder named reports in jenkins home directory. Note: Most of the scans such as like NodeJsScan, AuditJs, JSHint, etc. return a non-zero exit code, even on successful completion. Jenkins considers non-zero status code as FAILED and stops the build. To overcome this, you can add either of the following at the end of the scan commands to give a 0 status code. <scan command> || true OR <scan command>; echo $? > /dev/null Remove DVNA from Jenkins After the scans are complete, the containers running in Jenkins VM are stopped and removed. Since we're working with a containerized application (DVNA), we need to perform tests on the latest available image on DockerHub. Hence, we remove the existing local appsecco/dvna docker image to avoid running a container with older release of the application image. On the other hand, you don't need to remove the mysql:5.7 image, since we require v5.7 and not the latest version. Deploy DVNA to Production Finally, operations are performed on the Production VM over SSH (configured in the section titled SSH Connection Between VMs ). vars.env file is copied into Production server, and the two containers; dvna-app and dvna-mysql , are run. The application is now successfully deployed!","title":"CI/CD Pipeline for Deploying DVNA"}]}